# 一、综述

# 二、项目配置
## （一）XMem配置过程
### 1、环境搭建
Ubuntu18.04
```bash
cd /home/jiguotong/Projects/Github
git clone https://github.com/hkchengrex/XMem.git
cd XMem
conda create -n XMem python==3.8.0
conda activate XMem
conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch -c conda-forge #若速度较慢，在screen下安装
pip install opencv-python -i https://pypi.mirrors.ustc.edu.cn/simple/
pip install -r requirements.txt -i https://pypi.mirrors.ustc.edu.cn/simple/
```
```bash
#测试python以及torch是否可用
python
Python 3.7.16
>>>import torch   
>>>print(torch.__version__)
1.12.1
>>>print(torch.cuda.is_available())#cuda是否可用
true
>>>torch.cuda.device_count()#返回GPU的数量
```

### 2、数据集下载
```bash
export PYTHONPATH = .
python -m scripts.download_dataset
#若网络问题无法下载可手动下载之后按照./scripts/download_dataset.py里的进行部署
```

### 3、训练

### 4、推理
（1）推理执行
//下载预训练模型（若网络问题无法下载可手动下载之后放在./saves目录下）
```./scripts/download_models.sh```

![1685609452430](image/视频分割笔记/1685609452430.png)

```bash
#采用不同的数据集用不同的方式进行推理
#DAVIS 2017 validation:
python eval.py --output ../output/d17 --dataset D17

#DAVIS 2016 validation:
python eval.py --output ../output/d16 --dataset D16

#DAVIS 2017 test-dev:
python eval.py --output ../output/d17-td --dataset D17 --split test

#YouTubeVOS 2018 validation:
python eval.py --output ../output/y18 --dataset Y18

#Long-Time Video (3X) (note that mem_every, aka r, is set differently):
python eval.py --output ../output/lv3 --dataset LV3 --mem_every 10
```
（2）推理剖析
核心语句prob = processor.step(rgb, msk, labels, end=(ti==vid_length-1))，其中，rgb.shape(3,height,width)，是图片的真彩色值，msk语义分割的标签mask，labels是标签种类的枚举，特别的是，只有第一帧需要msk和labels，其他后续帧都是None.
prob:这一张图片中每个像素属于class中的每个类的概率集合,prob.shape(classes,height,width)
out_mask:结果数组,选取概率最大的一个类作为结果，out_mask.shape(height,width)
out_img:针对单个图片预测导出的图片，加入pallete（由L模式变为P模式）
prob->out_mask->out_img
在每一张图片的推理结束后，self.memory.set_hidden(hidden)来为下一帧分割做准备。

# torch函数应用
1、torch.argmax(input: Tensor, dim: Optional[_int]=None, keepdim: _bool=False, *, out: Optional[Tensor]=None)
返回指定维度最大值的序号（索引）。实际就是以该维度为标准划分为各个队伍，不个队伍的同一位置进行pk，选出最大的值所在的索引。
若x.shape(2,3,4),y=torch.argmax(x,dim=0),则y.shape(3,4)
若x.shape(2,3,4),y=torch.argmax(x,dim=1),则y.shape(2,4)
若x.shape(2,3,4),y=torch.argmax(x,dim=2),则y.shape(2,3)
```python
import torch

x = torch.rand(3,2,3)
print(x)
y0 = torch.argmax(x, dim=0)
print(y0)
y1 = torch.argmax(x, dim=1)
print(y1)
y2 = torch.argmax(x, dim=2)
print(y2)
```
![1685685696830](image/视频分割笔记/1685685696830.png)

2、DataLoader类
数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。
在训练模型时使用到此函数，用来把训练数据分成多个小组 ，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。
![1685699996707](image/视频分割笔记/1685699996707.png)
```python
"""
    批训练，把数据变成一小批一小批数据进行训练。
    DataLoader就是用来包装所使用的数据，每次抛出一批数据
"""
import torch
import torch.utils.data as Data

BATCH_SIZE = 5

x = torch.linspace(1, 10, 10)
y = torch.linspace(10, 1, 10)
# 把数据放在数据库中
torch_dataset = Data.TensorDataset(x, y)
loader = Data.DataLoader(
    # 从数据库中每次抽出batch size个样本
    dataset=torch_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=2,
)


def show_batch():
    for epoch in range(3):
        for step, (batch_x, batch_y) in enumerate(loader):
            # training
            print("steop:{}, batch_x:{}, batch_y:{}".format(step, batch_x, batch_y))


if __name__ == '__main__':
    show_batch()
```