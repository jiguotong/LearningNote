# 一、综述

# 二、项目配置

## （一）XMem配置过程

### 1、环境搭建

Ubuntu18.04

```bash
cd /home/jiguotong/Projects/Github
git clone https://github.com/hkchengrex/XMem.git
cd XMem
conda create -n XMem python==3.8.0
conda activate XMem
conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=11.3 -c pytorch -c conda-forge #若速度较慢，在screen下安装
pip install opencv-python -i https://pypi.mirrors.ustc.edu.cn/simple/
pip install -r requirements.txt -i https://pypi.mirrors.ustc.edu.cn/simple/
```

```bash
#测试python以及torch是否可用
python
Python 3.7.16
>>>import torch   
>>>print(torch.__version__)
1.12.1
>>>print(torch.cuda.is_available())#cuda是否可用
true
>>>torch.cuda.device_count()#返回GPU的数量
```

### 2、数据集下载

```bash
export PYTHONPATH=.
python -m scripts.download_datasets
#若网络问题无法下载可手动下载之后按照./scripts/download_dataset.py里的进行部署
```

### 3、训练
（1）训练执行
``python -m torch.distributed.run --master_port 25763 --nproc_per_node=2 train.py --exp_id retrain --stage 03``

如果是使用预训练模型进行精调，命令如下
``python -m torch.distributed.launch --master_port 25763 --nproc_per_node=2 train.py --exp_id retrain_stage3_only --stage 3 --load_network saves/XMem-s0.pth``
（2）代码调试配置
调试代码所用配置.launch
```json
{
            "name": "run_train.py",
            "type": "python",
            "request": "launch",
            "program": "train.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {
                "PYTHONPATH": "${workspaceRoot}"
            },
            "args": [
                //"-m=torch.distributed.run",
                //"--master_port=25763",
                //"--nproc_per_node=2",
                "--exp_id=retrain",
                "--stage=0",      
            ]
        },
```
train.py文件中加入以下代码
```python
# Init distributed environment
import os
os.environ['MASTER_ADDR'] = 'localhost'
os.environ['MASTER_PORT'] = '25763'
os.environ['RANK'] = '0'
os.environ['WORLD_SIZE'] = '1'
```
（3）训练剖析
训练分不同的阶段stage 0-3，可自选搭配，也可以使用预训练模型进行精调
model = XMemTrainer()，构造训练器
train_dataset = StaticTransformDataset() 从已有路径中构造数据集，每一个数据集都有一个构造数据集的类
model.train()，开始训练

从configutation.py获取参数 ->  
### 4、推理

（1）推理执行
//下载预训练模型（若网络问题无法下载可手动下载之后放在./saves目录下）
``./scripts/download_models.sh``

![1685609452430](image/视频分割笔记/1685609452430.png)

```bash
#采用不同的数据集用不同的方式进行推理
#DAVIS 2017 validation:
python eval.py --output ../output/d17 --dataset D17

#DAVIS 2016 validation:
python eval.py --output ../output/d16 --dataset D16

#DAVIS 2017 test-dev:
python eval.py --output ../output/d17-td --dataset D17 --split test

#YouTubeVOS 2018 validation:
python eval.py --output ../output/y18 --dataset Y18

#Long-Time Video (3X) (note that mem_every, aka r, is set differently):
python eval.py --output ../output/lv3 --dataset LV3 --mem_every 10
```

（2）推理剖析
核心语句prob = processor.step(rgb, msk, labels, end=(ti==vid_length-1))，其中，rgb.shape(3,height,width)，是图片的真彩色值，msk语义分割的标签mask，labels是标签种类的枚举，特别的是，只有第一帧需要msk和labels，其他后续帧都是None.
prob:这一张图片中每个像素属于class中的每个类的概率集合,prob.shape(classes,height,width)
out_mask:结果数组,选取概率最大的一个类作为结果，out_mask.shape(height,width)
out_img:针对单个图片预测导出的图片，加入pallete（由L模式变为P模式）
prob->out_mask->out_img
在每一张图片的推理结束后，self.memory.set_hidden(hidden)来为下一帧分割做准备。

# torch函数应用

1、torch.argmax(input: Tensor, dim: Optional[_int]=None, keepdim: _bool=False, *, out: Optional[Tensor]=None)
返回指定维度最大值的序号（索引）。实际就是以该维度为标准划分为各个队伍，不个队伍的同一位置进行pk，选出最大的值所在的索引。
若x.shape(2,3,4),y=torch.argmax(x,dim=0),则y.shape(3,4)
若x.shape(2,3,4),y=torch.argmax(x,dim=1),则y.shape(2,4)
若x.shape(2,3,4),y=torch.argmax(x,dim=2),则y.shape(2,3)

```python
import torch

x = torch.rand(3,2,3)
print(x)
y0 = torch.argmax(x, dim=0)
print(y0)
y1 = torch.argmax(x, dim=1)
print(y1)
y2 = torch.argmax(x, dim=2)
print(y2)
```

![1685685696830](image/视频分割笔记/1685685696830.png)

2、DataLoader类
数据加载器，结合了数据集和取样器，并且可以提供多个线程处理数据集。
在训练模型时使用到此函数，用来把训练数据分成多个小组 ，此函数每次抛出一组数据。直至把所有的数据都抛出。就是做一个数据的初始化。
![1685699996707](image/视频分割笔记/1685699996707.png)

```python
"""
    批训练，把数据变成一小批一小批数据进行训练。
    DataLoader就是用来包装所使用的数据，每次抛出一批数据
"""
import torch
import torch.utils.data as Data

BATCH_SIZE = 5

x = torch.linspace(1, 10, 10)
y = torch.linspace(10, 1, 10)
# 把数据放在数据库中
torch_dataset = Data.TensorDataset(x, y)
loader = Data.DataLoader(
    # 从数据库中每次抽出batch size个样本
    dataset=torch_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=2,
)


def show_batch():
    for epoch in range(3):
        for step, (batch_x, batch_y) in enumerate(loader):
            # training
            print("steop:{}, batch_x:{}, batch_y:{}".format(step, batch_x, batch_y))


if __name__ == '__main__':
    show_batch()
```

3、

https://github.com/suhwan-cho/TMO

## （二）TMO配置过程
### 1、环境搭建
torch==1.11.0
torchvision==0.12.0
pypng==0.0.21
opencv-python==4.7.0.72
numpy==1.22.0
scikit-image==0.19.3
### 2、数据集下载
详见https://github.com/suhwan-cho/TMO readme.md
DUTS:https://drive.google.com/file/d/1qCN_jnbmXLmyDzYQ-3AHzVeGE2TDEv0z/view
DAVIS:https://drive.google.com/file/d/1WReuSYQ7pORUbxda18-Rka076OX9mPdx/view
FBMS:https://drive.google.com/file/d/1_SAzXEuPDv9tPIdFdZD-ZXU_BgebAmDs/view
YouTube-Objects:https://drive.google.com/file/d/1fwW3vxRQ-uOg_qzzoYql6fGVzMvBcqlY/view

### 3、推理
+ 下载预训练模型https://drive.google.com/file/d/12k0iZhcP6Z8RdGKCKHvlZq5g9kNtj8wA/view 放到TMO/trained_model目录下
+ 在run.py的main()函数内可以选择test_davis/test_fbms/test_ytobj对不同的数据集进行推理
+ python run.py --test

ps:若要进行debug，配置launch.json文件
```json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "run_run.py",
            "type": "python",
            "request": "launch",
            "program": "run.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {
                "PYTHONPATH": "${workspaceRoot}"
            },
            "args": [
                "--test"
            ]
        }
    ]
}
```

### 4、训练