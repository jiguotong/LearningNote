{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十章 图像分类  \n",
    "## 10.1 传统的图像分类vs深度学习图像分类  \n",
    "- 传统的图像分类如下所示，先从用于训练的图像中提取**图像表征(image representation)**，并结合对应的标签信息训练一个图像分类的模型(分类器)，对于每一副测试图像，采用同样的表征提取过程得到其图像表征，并利用训练得到的分类器预测其所属类别。  \n",
    "![Alt text](image-1.png)  \n",
    "- 常用的提取图像表征的方法有sift、视觉词袋模型(BoF)等  \n",
    "- 基于深度卷积神经网络的图像分类  \n",
    "- 图像分类的常用度量，Top-K 错误率，指的是模型预测的前 K 个最可能类别中，不包含真实标签的样本比例。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 基于视觉词袋模型的图像分类算法  \n",
    "- 视觉词袋模型是一种提取图像表征的方法，主要是以下步骤：  \n",
    "  (1)从训练图像集中提取特征，形成特征库  \n",
    "  (2)对特征库中的特征向量进行聚类，构建\"视觉词典\"  \n",
    "  (3)用所学到的视觉词典对每幅图像的特征进行编码  \n",
    "  (4)基于特征编码对图像进行表征\n",
    "- 数据流分析  \n",
    "  一张(H，W)图像经过SIFT，得到N*128描述符，N为关键点个数  \n",
    "  对n张图像共得到N_total*128描述子，取kMeans，得到 K*128 视觉词典(聚类中心)  \n",
    "  统计单张图像的N个描述子分别对应视觉词典的哪个词，统计频次，得到 1*k 的图像表征，例如1,5,3,5,0,…,5,1 (共k个)，然后对该直方图进行归一化，此即为该图像的图像表征  \n",
    "- 改进：上述**基于整幅图像特征编码的直方图统计表征**会丢失图像特征的位置信息，即任意改变特征的位置，其词袋模型表征是不变的。因此引入**空间金字塔匹配(spatial pyramid matching, SPM)**算法提升词袋模型的表征能力。SPM通过对图像分块，单独对每一块进行上述词袋模型构建直方图表征。  \n",
    "- 得到图像表征之后，使用如上特征训练一个SVM分类器，进行图像分类。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 基于深度卷积网络的图像分类算法  \n",
    "- 使用ResNet34编程实现  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
